#!/usr/bin/env python3
"""
analyze_gee_data.py

Analyse avancÃ©e des donnÃ©es Google Earth Engine pour le SÃ©nÃ©gal
- Analyses statistiques dÃ©taillÃ©es
- DÃ©tection de tendances
- CorrÃ©lations entre variables
- GÃ©nÃ©ration de rapports
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# Configuration
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data" / "gee_senegal"
OUTPUT_DIR = BASE_DIR / "data" / "gee_senegal" / "analysis"

# Configuration des graphiques
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def load_all_data():
    """Charge toutes les donnÃ©es consolidÃ©es"""
    print("ğŸ“Š Chargement des donnÃ©es pour analyse...")
    
    processed_dir = DATA_DIR / "processed"
    if not processed_dir.exists():
        processed_dir = DATA_DIR
    
    consolidated_files = list(processed_dir.glob("*_consolidated_data.csv"))
    
    if not consolidated_files:
        print("âŒ Aucun fichier consolidÃ© trouvÃ©")
        return None
    
    all_data = []
    
    for file_path in consolidated_files:
        region_name = file_path.stem.replace('_consolidated_data', '').title()
        
        try:
            df = pd.read_csv(file_path)
            df['region'] = region_name
            df['date'] = pd.to_datetime(df['date'])
            all_data.append(df)
            
        except Exception as e:
            print(f"  âŒ Erreur {file_path.name}: {e}")
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… DonnÃ©es chargÃ©es: {len(combined_df):,} enregistrements, {len(all_data)} rÃ©gions")
        return combined_df
    
    return None

def analyze_data_availability(df):
    """Analyse la disponibilitÃ© des donnÃ©es"""
    print("ğŸ” Analyse de la disponibilitÃ© des donnÃ©es...")
    
    # CrÃ©er le dossier de sortie
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # Calculer les statistiques de disponibilitÃ©
    availability_stats = {}
    
    for col in df.select_dtypes(include=[np.number]).columns:
        total_count = len(df)
        available_count = df[col].notna().sum()
        availability_pct = (available_count / total_count) * 100
        
        availability_stats[col] = {
            'total': total_count,
            'available': available_count,
            'missing': total_count - available_count,
            'availability_pct': availability_pct
        }
    
    # CrÃ©er un graphique de disponibilitÃ©
    fig, ax = plt.subplots(figsize=(12, 8))
    
    variables = list(availability_stats.keys())
    percentages = [availability_stats[var]['availability_pct'] for var in variables]
    
    bars = ax.barh(variables, percentages)
    
    # Colorer les barres selon le pourcentage
    for i, (bar, pct) in enumerate(zip(bars, percentages)):
        if pct >= 80:
            bar.set_color('green')
        elif pct >= 50:
            bar.set_color('orange')
        else:
            bar.set_color('red')
    
    ax.set_xlabel('Pourcentage de DisponibilitÃ© (%)')
    ax.set_title('DisponibilitÃ© des DonnÃ©es par Variable')
    ax.set_xlim(0, 100)
    
    # Ajouter les pourcentages sur les barres
    for i, pct in enumerate(percentages):
        ax.text(pct + 1, i, f'{pct:.1f}%', va='center')
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'data_availability.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ“Š Graphique sauvegardÃ©: data_availability.png")
    
    return availability_stats

def analyze_temporal_trends(df):
    """Analyse les tendances temporelles"""
    print("ğŸ“ˆ Analyse des tendances temporelles...")
    
    # Variables clÃ©s Ã  analyser
    key_variables = []
    
    # Identifier les variables disponibles
    for pattern in ['temperature', 'precipitation', 'ndvi', 'evi']:
        matching_cols = [col for col in df.columns if pattern in col.lower() and df[col].notna().sum() > 100]
        if matching_cols:
            key_variables.append(matching_cols[0])
    
    if not key_variables:
        print("âš ï¸ Aucune variable clÃ© trouvÃ©e pour l'analyse temporelle")
        return None
    
    # CrÃ©er des moyennes mensuelles
    df['year_month'] = df['date'].dt.to_period('M')
    monthly_data = df.groupby('year_month')[key_variables].mean().reset_index()
    monthly_data['date'] = monthly_data['year_month'].dt.to_timestamp()
    
    # CrÃ©er le graphique
    fig, axes = plt.subplots(len(key_variables), 1, figsize=(15, 4*len(key_variables)))
    if len(key_variables) == 1:
        axes = [axes]
    
    for i, var in enumerate(key_variables):
        axes[i].plot(monthly_data['date'], monthly_data[var], linewidth=2)
        axes[i].set_title(f'Tendance Temporelle - {var}')
        axes[i].set_ylabel(var)
        axes[i].grid(True, alpha=0.3)
        
        # Ajouter une ligne de tendance
        x_numeric = np.arange(len(monthly_data))
        z = np.polyfit(x_numeric, monthly_data[var].dropna(), 1)
        p = np.poly1d(z)
        axes[i].plot(monthly_data['date'], p(x_numeric), "r--", alpha=0.8, label='Tendance')
        axes[i].legend()
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'temporal_trends.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ“ˆ Graphique sauvegardÃ©: temporal_trends.png")
    
    return monthly_data

def analyze_regional_differences(df):
    """Analyse les diffÃ©rences rÃ©gionales"""
    print("ğŸ—ºï¸ Analyse des diffÃ©rences rÃ©gionales...")
    
    # Variables numÃ©riques disponibles
    numeric_vars = [col for col in df.select_dtypes(include=[np.number]).columns 
                   if df[col].notna().sum() > 100]
    
    if not numeric_vars:
        print("âš ï¸ Aucune variable numÃ©rique trouvÃ©e")
        return None
    
    # Prendre les 4 premiÃ¨res variables les plus complÃ¨tes
    top_vars = sorted(numeric_vars, key=lambda x: df[x].notna().sum(), reverse=True)[:4]
    
    # CrÃ©er des moyennes par rÃ©gion
    regional_stats = df.groupby('region')[top_vars].mean()
    
    # CrÃ©er le graphique
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    for i, var in enumerate(top_vars):
        regional_stats[var].plot(kind='bar', ax=axes[i])
        axes[i].set_title(f'Moyennes RÃ©gionales - {var}')
        axes[i].set_ylabel(var)
        axes[i].tick_params(axis='x', rotation=45)
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'regional_differences.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ—ºï¸ Graphique sauvegardÃ©: regional_differences.png")
    
    return regional_stats

def analyze_correlations(df):
    """Analyse les corrÃ©lations entre variables"""
    print("ğŸ”— Analyse des corrÃ©lations...")
    
    # SÃ©lectionner les variables numÃ©riques avec suffisamment de donnÃ©es
    numeric_vars = [col for col in df.select_dtypes(include=[np.number]).columns 
                   if df[col].notna().sum() > 500]
    
    if len(numeric_vars) < 2:
        print("âš ï¸ Pas assez de variables pour l'analyse de corrÃ©lation")
        return None
    
    # Calculer la matrice de corrÃ©lation
    corr_matrix = df[numeric_vars].corr()
    
    # CrÃ©er le heatmap
    plt.figure(figsize=(12, 10))
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    
    sns.heatmap(
        corr_matrix, 
        mask=mask,
        annot=True, 
        cmap='RdBu_r', 
        center=0,
        square=True,
        fmt='.2f',
        cbar_kws={"shrink": .8}
    )
    
    plt.title('Matrice de CorrÃ©lation des Variables')
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ”— Graphique sauvegardÃ©: correlation_matrix.png")
    
    # Identifier les corrÃ©lations fortes
    strong_correlations = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.7:
                strong_correlations.append({
                    'var1': corr_matrix.columns[i],
                    'var2': corr_matrix.columns[j],
                    'correlation': corr_val
                })
    
    return corr_matrix, strong_correlations

def analyze_seasonal_patterns(df):
    """Analyse les patterns saisonniers"""
    print("ğŸŒ± Analyse des patterns saisonniers...")
    
    # Ajouter des variables temporelles
    df['month'] = df['date'].dt.month
    df['season'] = df['month'].map(lambda x: 'Saison sÃ¨che' if x in [11, 12, 1, 2, 3, 4, 5] else 'Saison des pluies')
    
    # Variables Ã  analyser
    seasonal_vars = []
    for pattern in ['temperature', 'precipitation', 'ndvi']:
        matching_cols = [col for col in df.columns if pattern in col.lower() and df[col].notna().sum() > 200]
        if matching_cols:
            seasonal_vars.append(matching_cols[0])
    
    if not seasonal_vars:
        print("âš ï¸ Aucune variable trouvÃ©e pour l'analyse saisonniÃ¨re")
        return None
    
    # CrÃ©er le graphique
    fig, axes = plt.subplots(len(seasonal_vars), 1, figsize=(12, 4*len(seasonal_vars)))
    if len(seasonal_vars) == 1:
        axes = [axes]
    
    for i, var in enumerate(seasonal_vars):
        seasonal_data = df.groupby(['month', 'season'])[var].mean().reset_index()
        
        for season in seasonal_data['season'].unique():
            season_data = seasonal_data[seasonal_data['season'] == season]
            axes[i].plot(season_data['month'], season_data[var], 
                        marker='o', linewidth=2, label=season)
        
        axes[i].set_title(f'Pattern Saisonnier - {var}')
        axes[i].set_xlabel('Mois')
        axes[i].set_ylabel(var)
        axes[i].set_xticks(range(1, 13))
        axes[i].legend()
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'seasonal_patterns.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸŒ± Graphique sauvegardÃ©: seasonal_patterns.png")
    
    return seasonal_data

def generate_analysis_report(df, availability_stats, strong_correlations):
    """GÃ©nÃ¨re un rapport d'analyse dÃ©taillÃ©"""
    print("ğŸ“‹ GÃ©nÃ©ration du rapport d'analyse...")
    
    report = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'total_records': len(df),
            'regions': df['region'].nunique(),
            'date_range': {
                'start': df['date'].min().isoformat(),
                'end': df['date'].max().isoformat()
            }
        },
        'data_availability': availability_stats,
        'strong_correlations': strong_correlations,
        'regional_summary': {},
        'key_findings': []
    }
    
    # Statistiques par rÃ©gion
    for region in df['region'].unique():
        region_data = df[df['region'] == region]
        report['regional_summary'][region] = {
            'records': len(region_data),
            'date_range': {
                'start': region_data['date'].min().isoformat(),
                'end': region_data['date'].max().isoformat()
            }
        }
    
    # Findings clÃ©s
    if availability_stats:
        best_var = max(availability_stats.keys(), key=lambda x: availability_stats[x]['availability_pct'])
        worst_var = min(availability_stats.keys(), key=lambda x: availability_stats[x]['availability_pct'])
        
        report['key_findings'].extend([
            f"Variable la plus complÃ¨te: {best_var} ({availability_stats[best_var]['availability_pct']:.1f}%)",
            f"Variable la moins complÃ¨te: {worst_var} ({availability_stats[worst_var]['availability_pct']:.1f}%)"
        ])
    
    if strong_correlations:
        report['key_findings'].append(f"{len(strong_correlations)} corrÃ©lations fortes dÃ©tectÃ©es (|r| > 0.7)")
    
    # Sauvegarder le rapport
    report_file = OUTPUT_DIR / 'analysis_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # CrÃ©er aussi un rapport markdown
    md_content = f"""# Rapport d'Analyse GEE SÃ©nÃ©gal

**GÃ©nÃ©rÃ© le:** {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')}

## ğŸ“Š RÃ©sumÃ© des DonnÃ©es

- **Enregistrements totaux:** {len(df):,}
- **RÃ©gions:** {df['region'].nunique()}
- **PÃ©riode:** {df['date'].min().strftime('%Y-%m-%d')} Ã  {df['date'].max().strftime('%Y-%m-%d')}

## ğŸ” DisponibilitÃ© des DonnÃ©es

| Variable | DisponibilitÃ© | Enregistrements |
|----------|---------------|-----------------|
"""
    
    if availability_stats:
        for var, stats in sorted(availability_stats.items(), 
                                key=lambda x: x[1]['availability_pct'], reverse=True):
            md_content += f"| {var} | {stats['availability_pct']:.1f}% | {stats['available']:,} |\n"
    
    md_content += f"""
## ğŸ”— CorrÃ©lations Fortes

"""
    
    if strong_correlations:
        for corr in strong_correlations:
            md_content += f"- **{corr['var1']}** â†” **{corr['var2']}**: r = {corr['correlation']:.3f}\n"
    else:
        md_content += "Aucune corrÃ©lation forte dÃ©tectÃ©e (|r| > 0.7)\n"
    
    md_content += f"""
## ğŸ“ˆ Graphiques GÃ©nÃ©rÃ©s

- `data_availability.png` - DisponibilitÃ© des donnÃ©es par variable
- `temporal_trends.png` - Tendances temporelles des variables clÃ©s
- `regional_differences.png` - DiffÃ©rences entre rÃ©gions
- `correlation_matrix.png` - Matrice de corrÃ©lation
- `seasonal_patterns.png` - Patterns saisonniers

## ğŸ—ºï¸ RÃ©gions AnalysÃ©es

"""
    
    for region in sorted(df['region'].unique()):
        region_data = df[df['region'] == region]
        md_content += f"- **{region}**: {len(region_data):,} enregistrements\n"
    
    # Sauvegarder le rapport markdown
    md_file = OUTPUT_DIR / 'analysis_report.md'
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"  ğŸ“‹ Rapport JSON: {report_file}")
    print(f"  ğŸ“‹ Rapport Markdown: {md_file}")
    
    return report

def main():
    """Fonction principale"""
    print("ğŸ”¬ Analyse AvancÃ©e des DonnÃ©es GEE SÃ©nÃ©gal")
    print("=" * 50)
    
    try:
        # Charger les donnÃ©es
        df = load_all_data()
        if df is None:
            return 1
        
        # Analyses
        availability_stats = analyze_data_availability(df)
        temporal_data = analyze_temporal_trends(df)
        regional_stats = analyze_regional_differences(df)
        corr_matrix, strong_correlations = analyze_correlations(df)
        seasonal_data = analyze_seasonal_patterns(df)
        
        # GÃ©nÃ©rer le rapport
        report = generate_analysis_report(df, availability_stats, strong_correlations)
        
        print(f"\nğŸ‰ Analyse terminÃ©e avec succÃ¨s!")
        print(f"ğŸ“ Dossier de sortie: {OUTPUT_DIR}")
        print(f"ğŸ“Š Graphiques gÃ©nÃ©rÃ©s: 5")
        print(f"ğŸ“‹ Rapports gÃ©nÃ©rÃ©s: 2")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'analyse: {e}")
        return 1

if __name__ == "__main__":
    exit(main())